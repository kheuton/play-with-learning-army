{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# add src to path\n",
    "import sys\n",
    "sys.path.append('/cluster/home/kheuto01/code/play-with-learning-army/src')\n",
    "\n",
    "# change directory to this files directory\n",
    "import os\n",
    "os.chdir('/cluster/home/kheuto01/code/play-with-learning-army')\n",
    "from data_loader import load_processed, make_dataset\n",
    "from embedder_registry import initialize_embedding, initialize_criteria_embedding, initialize_combiner\n",
    "from domain_models import initialize_domain_models\n",
    "from loss_opt import initialize_loss, initialize_optimizer\n",
    "import torch\n",
    "import yaml\n",
    "import transformers\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, roc_auc_score, average_precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_directory = '/cluster/tufts/hugheslab/kheuto01/sensemaking/bertfinetune_test/test15_lr1e-06_alpha0.1_beta0.01'\n",
    "problem_config_path = '/cluster/home/kheuto01/code/play-with-learning-army/config/problem_config.yaml'\n",
    "test_metrics_path = os.path.join(experiment_directory, 'test_metrics.csv')\n",
    "config_path = os.path.join(experiment_directory, 'config.yaml')\n",
    "model_path = os.path.join(experiment_directory, 'final_model.pth')\n",
    "hyper_config = yaml.load(open(config_path, 'r'), Loader=yaml.FullLoader)\n",
    "problem_config = yaml.load(open(problem_config_path, 'r'), Loader=yaml.FullLoader)\n",
    "num_domains = problem_config['num_domains']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dict = torch.load(model_path, weights_only=False, map_location=torch.device('cpu'))\n",
    "domain_model_dict = save_dict['domain_model_dict']\n",
    "embedder = save_dict['embed_func']\n",
    "embedder.device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'embedder': 'bert',\n",
       " 'criteria_embedder': 'identity',\n",
       " 'combiner': 'concatenate',\n",
       " 'opt_weight_decay': 0,\n",
       " 'device': 'cuda',\n",
       " 'finetune': True,\n",
       " 'wandb_project': 'sensemaking_bert_finetune_test',\n",
       " 'seed': 360,\n",
       " 'num_epochs': 1000,\n",
       " 'loss': 'l2sp',\n",
       " 'learning_rate': 1e-06,\n",
       " 'alpha': 0.1,\n",
       " 'beta': 0.01,\n",
       " 'batch_size': 32,\n",
       " 'num_folds': 1,\n",
       " 'experiment_name': 'test15_lr1e-06_alpha0.1_beta0.01_take3',\n",
       " 'train_x_file': '/cluster/home/kheuto01/code/play-with-learning-army/data/clean/test_15/retrain_x.csv',\n",
       " 'train_y_file': '/cluster/home/kheuto01/code/play-with-learning-army/data/clean/test_15/retrain_y.csv',\n",
       " 'val_x_file': '/cluster/home/kheuto01/code/play-with-learning-army/data/clean/test_15/test_x.csv',\n",
       " 'val_y_file': '/cluster/home/kheuto01/code/play-with-learning-army/data/clean/test_15/test_y.csv',\n",
       " 'test_x_file': '/cluster/home/kheuto01/code/play-with-learning-army/data/clean/test_15/test_x.csv',\n",
       " 'test_y_file': '/cluster/home/kheuto01/code/play-with-learning-army/data/clean/test_15/test_y.csv',\n",
       " 'train_metrics_path': '/cluster/tufts/hugheslab/kheuto01/sensemaking/bertfinetune_test/test15_lr1e-06_alpha0.1_beta0.01/train_metrics.csv',\n",
       " 'val_metrics_path': '/cluster/tufts/hugheslab/kheuto01/sensemaking/bertfinetune_test/test15_lr1e-06_alpha0.1_beta0.01/test_metrics.csv',\n",
       " 'final_model_path': '/cluster/tufts/hugheslab/kheuto01/sensemaking/bertfinetune_test/test15_lr1e-06_alpha0.1_beta0.01/final_model.pth'}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyper_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_test_features, processed_test_labels = load_processed(hyper_config['test_x_file'], \n",
    "                                                                hyper_config['test_y_file'])\n",
    "(xs, ys, problem_ids, student_ids) = make_dataset(processed_test_features, processed_test_labels)\n",
    "xs, ys, problem_ids, student_ids = embedder.preprocess_data((xs, ys, torch.tensor(problem_ids), torch.tensor(student_ids)), hyper_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preds, all_labels, all_weights, all_domains = [], [], [], []\n",
    "\n",
    "if isinstance(xs, transformers.BatchEncoding):\n",
    "    batch_length = len(next(iter(xs.values())))\n",
    "else:\n",
    "    batch_length = len(xs)\n",
    "    \n",
    "for i in range(batch_length):\n",
    "    if isinstance(xs, transformers.BatchEncoding):\n",
    "        x = {k: v[i].unsqueeze(0) for k, v in xs.items()}\n",
    "    else:\n",
    "        x = xs[i].unsqueeze(0)\n",
    "    y = ys[i]\n",
    "    p = problem_ids[i]\n",
    "    s = student_ids[i]\n",
    "\n",
    "    x_embed = embedder.forward(x)\n",
    "\n",
    "    criteria_counter = 0\n",
    "    for d in range(num_domains):\n",
    "        num_criteria = problem_config['problems'][p]['domains'][d][\"num_criteria\"]\n",
    "        for c in range(num_criteria):\n",
    "            c_embed = torch.tensor([c])\n",
    "            final_representation = torch.cat((x_embed, c_embed.unsqueeze(0)), dim=1)\n",
    "            y_pred = domain_model_dict[d](final_representation)\n",
    "            weight = 1/num_criteria\n",
    "\n",
    "            all_preds.append(y_pred.detach().cpu().numpy())\n",
    "            all_labels.append(y[criteria_counter].cpu().numpy())\n",
    "            all_weights.append(weight)\n",
    "            all_domains.append(d)\n",
    "            criteria_counter += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Metrics:\n",
      "Accuracy: 0.9210526315789473\n",
      "Precision: 0.8884615384615384\n",
      "Recall: 0.9352226720647774\n",
      "F1 Score: 0.9112426035502958\n",
      "ROC AUC: 0.9864504079918778\n",
      "Average Precision: 0.9828301936945492\n",
      "Binary Cross-Entropy Loss: 0.1291058510541916\n",
      "\n",
      "Weighted Metrics:\n",
      "Weighted Accuracy: 0.9378787878787879\n",
      "Weighted Precision: 0.9070048309178753\n",
      "Weighted Recall: 0.9422835633626102\n",
      "Weighted F1 Score: 0.9243076923076928\n",
      "Weighted ROC AUC: 0.9918502499334465\n",
      "Weighted Average Precision: 0.9883217108803226\n",
      "Weighted Binary Cross-Entropy Loss: 0.0583498515188694\n",
      "\n",
      "Metrics by Domain:\n",
      "\n",
      "Domain 0:\n",
      "accuracy: 0.9714285714285714\n",
      "precision: 0.9759036144578314\n",
      "recall: 0.9878048780487805\n",
      "f1: 0.9818181818181818\n",
      "roc_auc: 0.9946977730646872\n",
      "avg_precision: 0.998512347423429\n",
      "bce_loss: 0.05327007547020912\n",
      "weighted_accuracy: 0.9805555555555556\n",
      "weighted_precision: 0.983739837398374\n",
      "weighted_recall: 0.9877551020408163\n",
      "weighted_f1: 0.9857433808553973\n",
      "weighted_roc_auc: 0.9984383318544809\n",
      "weighted_avg_precision: 0.9992657503424226\n",
      "weighted_bce_loss: 0.02092500776052475\n",
      "\n",
      "Domain 1:\n",
      "accuracy: 1.0\n",
      "precision: 1.0\n",
      "recall: 1.0\n",
      "f1: 1.0\n",
      "roc_auc: 1.0\n",
      "avg_precision: 1.0\n",
      "bce_loss: 0.006456067319959402\n",
      "weighted_accuracy: 1.0\n",
      "weighted_precision: 1.0\n",
      "weighted_recall: 1.0\n",
      "weighted_f1: 1.0\n",
      "weighted_roc_auc: 1.0\n",
      "weighted_avg_precision: 1.0\n",
      "weighted_bce_loss: 0.004423640668392181\n",
      "\n",
      "Domain 2:\n",
      "accuracy: 1.0\n",
      "precision: 1.0\n",
      "recall: 1.0\n",
      "f1: 1.0\n",
      "roc_auc: 1.0\n",
      "avg_precision: 1.0\n",
      "bce_loss: 0.008035060949623585\n",
      "weighted_accuracy: 1.0\n",
      "weighted_precision: 1.0\n",
      "weighted_recall: 1.0\n",
      "weighted_f1: 1.0\n",
      "weighted_roc_auc: 1.0\n",
      "weighted_avg_precision: 1.0\n",
      "weighted_bce_loss: 0.008035060949623585\n",
      "\n",
      "Domain 3:\n",
      "accuracy: 0.8571428571428571\n",
      "precision: 0.7209302325581395\n",
      "recall: 0.9117647058823529\n",
      "f1: 0.8051948051948052\n",
      "roc_auc: 0.9614747307373654\n",
      "avg_precision: 0.9283186369651438\n",
      "bce_loss: 0.18898960947990417\n",
      "weighted_accuracy: 0.875\n",
      "weighted_precision: 0.7209302325581395\n",
      "weighted_recall: 0.9117647058823529\n",
      "weighted_f1: 0.8051948051948052\n",
      "weighted_roc_auc: 0.9681942544459644\n",
      "weighted_avg_precision: 0.9283186369651438\n",
      "weighted_bce_loss: 0.09457463026046753\n",
      "\n",
      "Domain 4:\n",
      "accuracy: 0.9\n",
      "precision: 0.8620689655172413\n",
      "recall: 0.8771929824561403\n",
      "f1: 0.8695652173913043\n",
      "roc_auc: 0.9684965100924353\n",
      "avg_precision: 0.9480851943057924\n",
      "bce_loss: 0.17723579704761505\n",
      "weighted_accuracy: 0.9027777777777778\n",
      "weighted_precision: 0.8787878787878792\n",
      "weighted_recall: 0.8592592592592594\n",
      "weighted_f1: 0.8689138576779029\n",
      "weighted_roc_auc: 0.9730699588477367\n",
      "weighted_avg_precision: 0.9550943719893886\n",
      "weighted_bce_loss: 0.0671674981713295\n",
      "\n",
      "Domain 5:\n",
      "accuracy: 0.9866666666666667\n",
      "precision: 1.0\n",
      "recall: 0.9642857142857143\n",
      "f1: 0.9818181818181818\n",
      "roc_auc: 0.9992401215805471\n",
      "avg_precision: 0.9987684729064038\n",
      "bce_loss: 0.022877287119627\n",
      "weighted_accuracy: 0.9888888888888889\n",
      "weighted_precision: 1.0\n",
      "weighted_recall: 0.9714285714285714\n",
      "weighted_f1: 0.9855072463768116\n",
      "weighted_roc_auc: 0.9994805194805194\n",
      "weighted_avg_precision: 0.9992063492063492\n",
      "weighted_bce_loss: 0.012109609320759773\n",
      "\n",
      "Domain 6:\n",
      "accuracy: 0.6333333333333333\n",
      "precision: 0.631578947368421\n",
      "recall: 0.75\n",
      "f1: 0.6857142857142857\n",
      "roc_auc: 0.84375\n",
      "avg_precision: 0.8974275362318841\n",
      "bce_loss: 0.640789270401001\n",
      "weighted_accuracy: 0.6333333333333333\n",
      "weighted_precision: 0.631578947368421\n",
      "weighted_recall: 0.75\n",
      "weighted_f1: 0.6857142857142857\n",
      "weighted_roc_auc: 0.84375\n",
      "weighted_avg_precision: 0.8974275362318841\n",
      "weighted_bce_loss: 0.3203946352005005\n",
      "\n",
      "Domain 7:\n",
      "accuracy: 1.0\n",
      "precision: 1.0\n",
      "recall: 1.0\n",
      "f1: 1.0\n",
      "roc_auc: 1.0\n",
      "avg_precision: 1.0\n",
      "bce_loss: 0.004826248623430729\n",
      "weighted_accuracy: 1.0\n",
      "weighted_precision: 1.0\n",
      "weighted_recall: 1.0\n",
      "weighted_f1: 1.0\n",
      "weighted_roc_auc: 1.0\n",
      "weighted_avg_precision: 1.0\n",
      "weighted_bce_loss: 0.004826248623430729\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, roc_auc_score, average_precision_score\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "all_preds_np = np.concatenate(all_preds).flatten()\n",
    "all_labels_np = np.array(all_labels).flatten()\n",
    "all_weights_np = np.array(all_weights)\n",
    "all_domains_np = np.array(all_domains)\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(all_labels_np, all_preds_np.round())\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(all_labels_np, all_preds_np.round(), average='binary')\n",
    "roc_auc = roc_auc_score(all_labels_np, all_preds_np)\n",
    "avg_precision = average_precision_score(all_labels_np, all_preds_np)\n",
    "bce_loss = F.binary_cross_entropy(torch.tensor(all_preds_np), torch.tensor(all_labels_np), reduction='mean').item()\n",
    "\n",
    "# Calculate weighted metrics\n",
    "weighted_accuracy = accuracy_score(all_labels_np, all_preds_np.round(), sample_weight=all_weights_np)\n",
    "weighted_precision, weighted_recall, weighted_f1, _ = precision_recall_fscore_support(all_labels_np, all_preds_np.round(), average='binary', sample_weight=all_weights_np)\n",
    "weighted_roc_auc = roc_auc_score(all_labels_np, all_preds_np, sample_weight=all_weights_np)\n",
    "weighted_avg_precision = average_precision_score(all_labels_np, all_preds_np, sample_weight=all_weights_np)\n",
    "weighted_bce_loss = F.binary_cross_entropy(torch.tensor(all_preds_np), torch.tensor(all_labels_np), weight=torch.tensor(all_weights_np), reduction='mean').item()\n",
    "\n",
    "# Calculate metrics by domain\n",
    "unique_domains = np.unique(all_domains_np)\n",
    "domain_metrics = {}\n",
    "for domain in unique_domains:\n",
    "    domain_mask = all_domains_np == domain\n",
    "    domain_preds = all_preds_np[domain_mask]\n",
    "    domain_labels = all_labels_np[domain_mask]\n",
    "    domain_weights = all_weights_np[domain_mask]\n",
    "    \n",
    "    domain_accuracy = accuracy_score(domain_labels, domain_preds.round())\n",
    "    domain_precision, domain_recall, domain_f1, _ = precision_recall_fscore_support(domain_labels, domain_preds.round(), average='binary')\n",
    "    domain_roc_auc = roc_auc_score(domain_labels, domain_preds)\n",
    "    domain_avg_precision = average_precision_score(domain_labels, domain_preds)\n",
    "    domain_bce_loss = F.binary_cross_entropy(torch.tensor(domain_preds), torch.tensor(domain_labels), reduction='mean').item()\n",
    "    \n",
    "    domain_weighted_accuracy = accuracy_score(domain_labels, domain_preds.round(), sample_weight=domain_weights)\n",
    "    domain_weighted_precision, domain_weighted_recall, domain_weighted_f1, _ = precision_recall_fscore_support(domain_labels, domain_preds.round(), average='binary', sample_weight=domain_weights)\n",
    "    domain_weighted_roc_auc = roc_auc_score(domain_labels, domain_preds, sample_weight=domain_weights)\n",
    "    domain_weighted_avg_precision = average_precision_score(domain_labels, domain_preds, sample_weight=domain_weights)\n",
    "    domain_weighted_bce_loss = F.binary_cross_entropy(torch.tensor(domain_preds), torch.tensor(domain_labels), weight=torch.tensor(domain_weights), reduction='mean').item()\n",
    "    \n",
    "    domain_metrics[domain] = {\n",
    "        'accuracy': domain_accuracy,\n",
    "        'precision': domain_precision,\n",
    "        'recall': domain_recall,\n",
    "        'f1': domain_f1,\n",
    "        'roc_auc': domain_roc_auc,\n",
    "        'avg_precision': domain_avg_precision,\n",
    "        'bce_loss': domain_bce_loss,\n",
    "        'weighted_accuracy': domain_weighted_accuracy,\n",
    "        'weighted_precision': domain_weighted_precision,\n",
    "        'weighted_recall': domain_weighted_recall,\n",
    "        'weighted_f1': domain_weighted_f1,\n",
    "        'weighted_roc_auc': domain_weighted_roc_auc,\n",
    "        'weighted_avg_precision': domain_weighted_avg_precision,\n",
    "        'weighted_bce_loss': domain_weighted_bce_loss\n",
    "    }\n",
    "\n",
    "# Print results\n",
    "print(\"Overall Metrics:\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(f\"ROC AUC: {roc_auc}\")\n",
    "print(f\"Average Precision: {avg_precision}\")\n",
    "print(f\"Binary Cross-Entropy Loss: {bce_loss}\")\n",
    "\n",
    "print(\"\\nWeighted Metrics:\")\n",
    "print(f\"Weighted Accuracy: {weighted_accuracy}\")\n",
    "print(f\"Weighted Precision: {weighted_precision}\")\n",
    "print(f\"Weighted Recall: {weighted_recall}\")\n",
    "print(f\"Weighted F1 Score: {weighted_f1}\")\n",
    "print(f\"Weighted ROC AUC: {weighted_roc_auc}\")\n",
    "print(f\"Weighted Average Precision: {weighted_avg_precision}\")\n",
    "print(f\"Weighted Binary Cross-Entropy Loss: {weighted_bce_loss}\")\n",
    "\n",
    "print(\"\\nMetrics by Domain:\")\n",
    "for domain, metrics in domain_metrics.items():\n",
    "    print(f\"\\nDomain {domain}:\")\n",
    "    for metric_name, metric_value in metrics.items():\n",
    "        print(f\"{metric_name}: {metric_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learningarmy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
